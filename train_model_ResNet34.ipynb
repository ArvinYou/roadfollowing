{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#from torch2trt import torch2trt, TRTModule\n",
    "#import tensorrt as trt\n",
    "import PIL.Image\n",
    "import glob\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class RoadDataset(Dataset):\n",
    "    def __init__(self, directory, mode='train'):\n",
    "        self.directory = directory\n",
    "        self.mode = mode\n",
    "        self.image_size = 224\n",
    "        self.samples = []\n",
    "        \n",
    "        if not os.path.isdir(directory):\n",
    "            raise ValueError(f\"Catalogue does not exist: {directory}\")\n",
    "        \n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.endswith(('.jpg', '.png')):\n",
    "                parts = filename.split('_')\n",
    "                if len(parts) < 3:\n",
    "                    print(f\"Skip file {filename}: \")\n",
    "                    continue\n",
    "                try:\n",
    "                    x = int(parts[1])\n",
    "                    y = int(parts[2].split('_')[0])  # \n",
    "                    \n",
    "                    x_normalized = (x - (self.image_size / 2)) / (self.image_size / 2)\n",
    "                    y_normalized = (y - (self.image_size / 2)) / (self.image_size / 2)\n",
    "                    \n",
    "                    self.samples.append((\n",
    "                        os.path.join(directory, filename),\n",
    "                        (x_normalized, y_normalized)\n",
    "                    ))\n",
    "                except ValueError as e:\n",
    "                    print(f\"error  {filename} : {str(e)}\")\n",
    "                    continue\n",
    "        \n",
    "        if len(self.samples) == 0:\n",
    "            raise ValueError(f\"{directory}No valid images found\")\n",
    "        \n",
    "        print(f\"Valid images founded {len(self.samples)} \")\n",
    "        self._check_distribution()\n",
    "        \n",
    "        self.transform = self._get_transform()\n",
    "                \n",
    "    def _get_transform(self):\n",
    "        base_transforms = [\n",
    "            transforms.Resize((self.image_size, self.image_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                [0.485, 0.456, 0.406],\n",
    "                [0.229, 0.224, 0.225]\n",
    "            )\n",
    "        ]\n",
    "        if self.mode == 'train':\n",
    "            augmentations = [\n",
    "                transforms.ColorJitter(\n",
    "                    brightness=0.2, \n",
    "                    contrast=0.2, \n",
    "                    saturation=0.2, \n",
    "                    hue=0.1\n",
    "                ),\n",
    "                transforms.GaussianBlur(3, sigma=(0.1, 0.2))\n",
    "            ]\n",
    "            return transforms.Compose(augmentations + base_transforms)\n",
    "        else:\n",
    "            return transforms.Compose(base_transforms)\n",
    "                \n",
    "    def _check_distribution(self):\n",
    "        x_coords = [coords[0] for _, coords in self.samples]\n",
    "        y_coords = [coords[1] for _, coords in self.samples]\n",
    "        \n",
    "        print(\"\\nData distribution statistics:\")\n",
    "        print(f\"X range: [{min(x_coords):.2f}, {max(x_coords):.2f}]\")\n",
    "        print(f\"Y range: [{min(y_coords):.2f}, {max(y_coords):.2f}]\")\n",
    "        print(f\"X Mean: {sum(x_coords)/len(x_coords):.2f}\")\n",
    "        print(f\"Y Mean: {sum(y_coords)/len(y_coords):.2f}\")\n",
    "        \n",
    "        num_left = sum(1 for x in x_coords if x < 0)\n",
    "        num_right = sum(1 for x in x_coords if x > 0)\n",
    "        print(f\"\\ndistribution:\")\n",
    "        print(f\"Number of samples on the left side: {num_left}\")\n",
    "        print(f\"Number of samples on the right side: {num_right}\")\n",
    "        if abs(num_left - num_right) > len(x_coords) * 0.2: \n",
    "            print(\"There may be a left-right imbalance in the data\")\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, (x, y) = self.samples[idx]\n",
    "\n",
    "        if not os.path.exists(img_path):\n",
    "            raise FileNotFoundError(f\"File does not exist: {img_path}\")\n",
    "        \n",
    "        image = PIL.Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if image.size[0] == 0 or image.size[1] == 0:\n",
    "            raise ValueError(f\"Invalid image size: {img_path}\")\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        label = torch.tensor([x, y], dtype=torch.float32)\n",
    "        \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into train and test sets\n",
    "Once we read dataset, we will split data set in train and test sets. In this example we split train and test a 90%-10%. The test set will be used to verify the accuracy of the model we train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RoadDataset('road_following/dataset_xy')\n",
    "\n",
    "test_percent = 0.1\n",
    "num_test = int(test_percent * len(dataset))\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - num_test, num_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Use of cuda: {device}')\n",
    "\n",
    "best_batch_size = 8\n",
    "best_lr = 0.0011029876079911261\n",
    "best_weight_decay = 0.0003940097627656374\n",
    "NUM_EPOCHS = 30\n",
    "BEST_MODEL_PATH = 'best_road_model.pth'\n",
    "\n",
    "\n",
    "data_directory = 'road_following/dataset_xy'  \n",
    "\n",
    "train_dataset = RoadDataset(directory=data_directory, mode='train')\n",
    "test_dataset = RoadDataset(directory='road_following/val', mode='test')\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=best_batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=best_batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "model = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
    "model.fc = torch.nn.Linear(512, 2)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=best_lr, weight_decay=best_weight_decay)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "best_loss = float('inf')\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{NUM_EPOCHS}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in tqdm(train_loader, desc='шонч╗Г'):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    train_losses.append(epoch_loss)\n",
    "    print(f'loss: {epoch_loss:.4f}')\n",
    "\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(test_loader, desc='validate'):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "    epoch_loss = running_loss / len(test_dataset)\n",
    "    test_losses.append(epoch_loss)\n",
    "    print(f'validation loss: {epoch_loss:.4f}')\n",
    "\n",
    "\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        print(f'The new best model is saved in {BEST_MODEL_PATH} validation loss: {best_loss:.4f}')\n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_percent = 0.1\n",
    "num_test = int(test_percent * len(dataset))\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - num_test, num_test])\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "   \n",
    "    batch_size = trial.suggest_categorical('batch_size', [8, 16, 32, 64])\n",
    "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
    "    weight_decay = trial.suggest_loguniform('weight_decay', 1e-5, 1e-1)\n",
    "\n",
    "   \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    model = models.resnet34(pretrained=True)\n",
    "    model.fc = torch.nn.Linear(512, 2)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    NUM_EPOCHS = 10  \n",
    "    BEST_MODEL_PATH = f'best_model_trial_{trial.number}.pth'\n",
    "    best_loss = float('inf')\n",
    "\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for images, labels in iter(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = F.mse_loss(outputs, labels)\n",
    "            train_loss += float(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in iter(test_loader):\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = F.mse_loss(outputs, labels)\n",
    "                test_loss += float(loss)\n",
    "        test_loss /= len(test_loader)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        print(f'Trial {trial.number}, Epoch {epoch}, Train Loss: {train_loss}, Test Loss: {test_loss}')\n",
    "\n",
    "        if test_loss < best_loss:\n",
    "            best_loss = test_loss\n",
    "            torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "\n",
    "     \n",
    "        trial.report(test_loss, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return best_loss\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print('best trial:')\n",
    "trial = study.best_trial\n",
    "\n",
    "print('  Minimum loss value: {}'.format(trial.value))\n",
    "print('  Optimal hyperparameters: ')\n",
    "for key, value in trial.params.items():\n",
    "    print('    {}: {}'.format(key, value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoadFollowingModel(nn.Module):\n",
    "    def __init__(self, num_outputs=2):\n",
    "        super(RoadFollowingModel, self).__init__()\n",
    "        \n",
    "        self.model = models.resnet34(pretrained=True)\n",
    "        \n",
    "        # хЗНч╡РхЙНщЭвх▒дя╝МхПкшиУч╖┤цЬАх╛Мф╕Ах▒д\n",
    "        for param in self.model.layer1.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.model.layer2.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        num_ftrs = self.model.fc.in_features\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_outputs)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "model = RoadFollowingModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet model has fully connect (fc) final layer with 512 as ``in_features`` and we will be training for regression thus ``out_features`` as 1\n",
    "\n",
    "Finally, we transfer our model for execution on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = torch.nn.Linear(512, 2)\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, num_epochs=50, device='cuda'):\n",
    "    print(\"щЦЛхзЛшиУч╖┤цибхЮЛ...\")\n",
    "    \n",
    "    scaler = GradScaler()\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    optimizer = optim.AdamW([\n",
    "        {'params': model.model.layer3.parameters(), 'lr': 1e-4},\n",
    "        {'params': model.model.layer4.parameters(), 'lr': 2e-4},\n",
    "        {'params': model.model.fc.parameters(), 'lr': 5e-4}\n",
    "    ], weight_decay=0.01)\n",
    "    \n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer, \n",
    "        mode='min', \n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-6, \n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_mae = []\n",
    "    val_mae = []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    os.makedirs('checkpoints', exist_ok=True)\n",
    "    \n",
    "    early_stopping_patience = 10\n",
    "    early_stopping_counter = 0\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"ф╜┐чФи GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "                current_loader = train_loader  \n",
    "            else:\n",
    "                model.eval()\n",
    "                current_loader = val_loader \n",
    "            \n",
    "            running_loss = 0.0\n",
    "            all_targets = []\n",
    "            all_outputs = []\n",
    "\n",
    "            with tqdm(current_loader, desc=phase) as pbar: \n",
    "                for inputs, targets in pbar:\n",
    "                    inputs = inputs.to(device)\n",
    "                    targets = targets.to(device)\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        with torch.set_grad_enabled(phase == 'train'):\n",
    "                            outputs = model(inputs)\n",
    "                            loss = criterion(outputs, targets)\n",
    "                            \n",
    "                            if phase == 'train':\n",
    "                                scaler.scale(loss).backward()\n",
    "                                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                                scaler.step(optimizer)\n",
    "                                scaler.update()\n",
    "                    \n",
    "                    all_outputs.append(outputs.detach().cpu())\n",
    "                    all_targets.append(targets.detach().cpu())\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    \n",
    "                    pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "            \n",
    "            epoch_loss = running_loss / len(current_loader.dataset)  \n",
    "            all_outputs = torch.cat(all_outputs).numpy()\n",
    "            all_targets = torch.cat(all_targets).numpy()\n",
    "            epoch_mae = mean_absolute_error(all_targets, all_outputs)\n",
    "            \n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} MAE: {epoch_mae:.4f}')\n",
    "            \n",
    "            if phase == 'train':\n",
    "                train_losses.append(epoch_loss)\n",
    "                train_mae.append(epoch_mae)\n",
    "            else:\n",
    "                val_losses.append(epoch_loss)\n",
    "                val_mae.append(epoch_mae)\n",
    "                \n",
    "                scheduler.step(epoch_loss)\n",
    "                \n",
    "                if epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    early_stopping_counter = 0\n",
    "                    \n",
    "                    torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'model_state_dict': best_model_wts,\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'scheduler_state_dict': scheduler.state_dict(),\n",
    "                        'loss': best_loss,\n",
    "                        'train_losses': train_losses,\n",
    "                        'val_losses': val_losses,\n",
    "                        'train_mae': train_mae,\n",
    "                        'val_mae': val_mae,\n",
    "                        'scaler_state_dict': scaler.state_dict()\n",
    "                    }, 'best_steering_model_ResNet34_xy.pth')\n",
    "                else:\n",
    "                    early_stopping_counter += 1\n",
    "                    \n",
    "                if early_stopping_counter >= early_stopping_patience:\n",
    "                    break\n",
    "                    \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'loss': epoch_loss,\n",
    "                'train_losses': train_losses,\n",
    "                'val_losses': val_losses,\n",
    "                'train_mae': train_mae,\n",
    "                'val_mae': val_mae,\n",
    "                'scaler_state_dict': scaler.state_dict()\n",
    "            }, f'checkpoints/checkpoint_epoch_{epoch+1}.pth')\n",
    "            \n",
    "            plot_training_results(\n",
    "                train_losses, \n",
    "                val_losses, \n",
    "                train_mae, \n",
    "                val_mae,\n",
    "                save_path=f'checkpoints/training_curves_epoch_{epoch+1}.png'\n",
    "            )\n",
    "        \n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f'Current learning rate: {current_lr:.2e}')\n",
    "        print()\n",
    "        \n",
    "        if early_stopping_counter >= early_stopping_patience:\n",
    "            break\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    np.save('checkpoints/training_history.npy', {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_mae': train_mae,\n",
    "        'val_mae': val_mae,\n",
    "        'final_learning_rate': current_lr,\n",
    "        'best_loss': best_loss\n",
    "    })\n",
    "    \n",
    "    return model, train_losses, val_losses, train_mae, val_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, train_losses, val_losses, train_mae, val_mae = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=test_loader,\n",
    "    num_epochs=50,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(NUM_EPOCHS), train_losses, label='Training Loss', color='blue')\n",
    "plt.plot(range(NUM_EPOCHS), test_losses, label='Testing Loss', color='orange')\n",
    "plt.title('Training and Testing Loss Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "car",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
